{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from pymongo import MongoClient\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataframe(tab):\n",
    "\n",
    "    dataSet = pd.DataFrame()    \n",
    "    dataSet[\"id\"] = [tweet['id'] for tweet in tab.find()]\n",
    "    dataSet[\"text\"] = [tweet['text'] for tweet in tab.find()]\n",
    "    dataSet[\"created_at\"] = [tweet['created_at'] for tweet in tab.find()]\n",
    "    dataSet[\"favorite_count\"] = [tweet['favorite_count'] for tweet in tab.find()]\n",
    "    dataSet[\"source\"] = [tweet['source'] for tweet in tab.find()]\n",
    "    dataSet[\"user_id\"] = [tweet['user']['id'] for tweet in tab.find()]\n",
    "    dataSet[\"user_screen_name\"] = [tweet['user']['screen_name'] for tweet in tab.find()]\n",
    "    dataSet[\"user_name\"] = [tweet['user']['name'] for tweet in tab.find()]\n",
    "    dataSet[\"user_created_at\"] = [tweet['user']['created_at'] for tweet in tab.find()]\n",
    "    dataSet[\"user_description\"] = [tweet['user']['description'] for tweet in tab.find()]\n",
    "    dataSet[\"user_followers_count\"] = [tweet['user']['followers_count'] for tweet in tab.find()]\n",
    "    dataSet[\"user_friends_count\"] = [tweet['user']['friends_count'] for tweet in tab.find()]\n",
    "    dataSet[\"user_location\"] = [tweet['user']['location'] for tweet in tab.find()]\n",
    "    dataSet[\"user_time_zone\"] = [tweet['user']['time_zone'] for tweet in tab.find()]\n",
    "\n",
    "    return dataSet.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataframe2(tab1, tab2):\n",
    "    df1 = get_dataframe(tab1)\n",
    "    df2 = get_dataframe(tab2)\n",
    "    df = pd.concat([df1, df2])\n",
    "    return df.drop_duplicates()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_sent(score):\n",
    "    if score > 0 :\n",
    "        return \"Pos\"\n",
    "    elif score < 0:\n",
    "        return \"Neg\"\n",
    "    else:\n",
    "        return \"Neu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_week(date_time):\n",
    "    \n",
    "    day7 = timedelta(days=7)\n",
    "    date_slected = datetime.date(2016,1,9)\n",
    "    all_date =[date_slected]\n",
    "    for i in range(51):\n",
    "        date_slected = date_slected + day7\n",
    "        all_date.append(date_slected)\n",
    "\n",
    "    week_firstDate = pd.DataFrame()\n",
    "    week_firstDate['firstData'] = all_date\n",
    "    week_firstDate['week'] = range(1,53)\n",
    "    \n",
    "    for i in range(52):\n",
    "        if date_time.date() <= week_firstDate['firstData'][i]:\n",
    "            return week_firstDate['week'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def info_twitter_song(tab):\n",
    "\n",
    "    df= get_dataframe(tab)\n",
    "    df['sent_score'] = df['text'].map(lambda x : TextBlob(x).sentiment.polarity)\n",
    "    df['sent_category'] = df['sent_score'].map(get_category_sent)\n",
    "    df['pos'] = df['sent_category'].map(lambda x: 1 if x == 'Pos' else 0)\n",
    "    df['neg'] = df['sent_category'].map(lambda x: 1 if x == 'Neg' else 0)\n",
    "    df['neu'] = df['sent_category'].map(lambda x: 1 if x == 'Neu' else 0)\n",
    "    df['created_at_time'] = df['created_at'].map(lambda x : datetime.datetime.strptime(x, \"%a %b %d %H:%M:%S +0000 %Y\"))\n",
    "    df['created_at_time_min'] = df['created_at_time']\n",
    "    df['created_at_time_max'] = df['created_at_time']\n",
    "    df['created_at_time_date'] = df['created_at_time'].map(lambda x : x.date())\n",
    "    df['week_from_one'] = df['created_at_time'].map(find_week)\n",
    "    df['count'] = 1\n",
    "\n",
    "    col_list = ['week_from_one']\n",
    "    agg_dic = {'favorite_count':sum, 'count':sum, 'pos':sum, 'neg':sum, 'neu':sum,'created_at_time_min': min,\\\n",
    "               'created_at_time_max': max}\n",
    "    grouped = df.groupby(col_list).agg(agg_dic)\n",
    "    grouped = grouped.reset_index()\n",
    "\n",
    "    grouped['neg_rate']=1.0*grouped['neg']/grouped['count']\n",
    "    grouped['pos_rate']=1.0*grouped['pos']/grouped['count']\n",
    "    grouped['neu_rate']=1.0*grouped['neu']/grouped['count']\n",
    "    grouped['ratio_pos_neg']=1.0*(grouped['pos']+1)/(grouped['neg'] +1)\n",
    "    grouped['favorite_rate']=1.0*grouped['favorite_count']/grouped['count']\n",
    "\n",
    "    #selected_col = ['week_from_one','count','pos_rate','neg_rate', 'neu_rate','ratio_pos_neg','favorite_rate']\n",
    "    #slected = grouped[selected_col]\n",
    "    slected = grouped\n",
    "    return slected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info_twitter_song2(tab1, tab2):\n",
    "\n",
    "    df= get_dataframe2(tab1, tab2)\n",
    "    df['sent_score'] = df['text'].map(lambda x : TextBlob(x).sentiment.polarity)\n",
    "    df['sent_category'] = df['sent_score'].map(get_category_sent)\n",
    "    df['pos'] = df['sent_category'].map(lambda x: 1 if x == 'Pos' else 0)\n",
    "    df['neg'] = df['sent_category'].map(lambda x: 1 if x == 'Neg' else 0)\n",
    "    df['neu'] = df['sent_category'].map(lambda x: 1 if x == 'Neu' else 0)\n",
    "    df['created_at_time'] = df['created_at'].map(lambda x : datetime.datetime.strptime(x, \"%a %b %d %H:%M:%S +0000 %Y\"))\n",
    "    df['created_at_time_min'] = df['created_at_time']\n",
    "    df['created_at_time_max'] = df['created_at_time']\n",
    "    df['created_at_time_date'] = df['created_at_time'].map(lambda x : x.date())\n",
    "    df['week_from_one'] = df['created_at_time'].map(find_week)\n",
    "    df['count'] = 1\n",
    "\n",
    "    col_list = ['week_from_one']\n",
    "    agg_dic = {'favorite_count':sum, 'count':sum, 'pos':sum, 'neg':sum, 'neu':sum,'created_at_time_min': min,\\\n",
    "               'created_at_time_max': max}\n",
    "    grouped = df.groupby(col_list).agg(agg_dic)\n",
    "    grouped = grouped.reset_index()\n",
    "\n",
    "    grouped['neg_rate']=1.0*grouped['neg']/grouped['count']\n",
    "    grouped['pos_rate']=1.0*grouped['pos']/grouped['count']\n",
    "    grouped['neu_rate']=1.0*grouped['neu']/grouped['count']\n",
    "    grouped['ratio_pos_neg']=1.0*(grouped['pos']+1)/(grouped['neg'] +1)\n",
    "    grouped['favorite_rate']=1.0*grouped['favorite_count']/grouped['count']\n",
    "\n",
    "    #selected_col = ['week_from_one','count','pos_rate','neg_rate', 'neu_rate','ratio_pos_neg','favorite_rate']\n",
    "    #slected = grouped[selected_col]\n",
    "    slected = grouped\n",
    "    return slected\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info_raw_twitter_song2(song_id,tab1, tab2):\n",
    "\n",
    "    df= get_dataframe2(tab1, tab2)\n",
    "    df['sent_score'] = df['text'].map(lambda x : TextBlob(x).sentiment.polarity)\n",
    "    df['sent_category'] = df['sent_score'].map(get_category_sent)\n",
    "    df['pos'] = df['sent_category'].map(lambda x: 1 if x == 'Pos' else 0)\n",
    "    df['neg'] = df['sent_category'].map(lambda x: 1 if x == 'Neg' else 0)\n",
    "    df['neu'] = df['sent_category'].map(lambda x: 1 if x == 'Neu' else 0)\n",
    "    df['created_at_time'] = df['created_at'].map(lambda x : datetime.datetime.strptime(x, \"%a %b %d %H:%M:%S +0000 %Y\"))\n",
    "    df['created_at_time_date'] = df['created_at_time'].map(lambda x : x.date())\n",
    "    df['week_from_one'] = df['created_at_time'].map(find_week)\n",
    "    df['song_id'] = song_id\n",
    "\n",
    "    selected_col = [\"song_id\", \"created_at_time\",\"created_at_time_date\",\"week_from_one\", \"favorite_count\",\\\n",
    "                    \"sent_score\",\"sent_category\", \"pos\",\"neg\", \"neu\"]\n",
    "    \n",
    "    return df[selected_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_billboard(billboard_filename_path):\n",
    "\n",
    "    df2 = pd.read_csv(billboard_filename_path, names=['long_artist', 'last_date','rank','song'])\n",
    "    df2['last_date_time'] = df2['last_date'].map(lambda x : datetime.datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "    df2['week_from_one'] = df2['last_date_time'].map(find_week)\n",
    "    df2[\"artist\"] = df2[\"long_artist\"].map(lambda x : x.split('featuring')[0])\n",
    "    df2[\"ID\"] = df2[\"song\"] + \"%\" +  df2[\"artist\"]\n",
    "    \n",
    "    df= df2.pivot('ID', 'week_from_one', 'rank')\n",
    "    df[\"ID\"] = df.index\n",
    "    df[\"song\"] = df[\"ID\"].map(lambda x : x.split('%')[0])\n",
    "    df[\"artist\"] = df[\"ID\"].map(lambda x : x.split('%')[1])\n",
    "    df.fillna(101,inplace=True)\n",
    "    df.index = range(1,len(df)+1)\n",
    "    df[\"IDN\"] = df.index\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../data/billboard_result_20150103_20160430.csv\", names=['long_artist', 'last_date','rank','song'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'last_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-3eff7a5be79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'last_data'"
     ]
    }
   ],
   "source": [
    "df2['last_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_artist</th>\n",
       "      <th>last_date</th>\n",
       "      <th>rank</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PANIC! AT THE DISCO</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>96</td>\n",
       "      <td>Victorious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PARTYNEXTDOOR featuring DRAKE</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>97</td>\n",
       "      <td>Come And See Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FLUME featuring KAI</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>98</td>\n",
       "      <td>Never Be Like You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>KANYE WEST</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>99</td>\n",
       "      <td>Feedback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ERIC CHURCH</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>100</td>\n",
       "      <td>Record Year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      long_artist   last_date rank               song\n",
       "95            PANIC! AT THE DISCO  2016-04-30  96          Victorious\n",
       "96  PARTYNEXTDOOR featuring DRAKE  2016-04-30  97     Come And See Me\n",
       "97            FLUME featuring KAI  2016-04-30  98   Never Be Like You\n",
       "98                     KANYE WEST  2016-04-30  99            Feedback\n",
       "99                    ERIC CHURCH  2016-04-30  100        Record Year"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data 'date' does not match format '%Y-%m-%d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c8d63f447204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurrent_billboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_billboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/billboard_result_20150103_20160430.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-2aaa8ee345b5>\u001b[0m in \u001b[0;36mget_billboard\u001b[0;34m(billboard_filename_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbillboard_filename_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'long_artist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'last_date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'song'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_date_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_from_one'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_date_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_week\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"artist\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"long_artist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'featuring'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2052\u001b[0m                                      index=self.index).__finalize__(self)\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m             return self._constructor(mapped,\n\u001b[1;32m   2056\u001b[0m                                      index=self.index).__finalize__(self)\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62578)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-2aaa8ee345b5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbillboard_filename_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'long_artist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'last_date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'song'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_date_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_from_one'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_date_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_week\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"artist\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"long_artist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'featuring'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/_strptime.pyc\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0;32m--> 325\u001b[0;31m                          (data_string, format))\n\u001b[0m\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n",
      "\u001b[0;31mValueError\u001b[0m: time data 'date' does not match format '%Y-%m-%d'"
     ]
    }
   ],
   "source": [
    "current_billboard = get_billboard(\"../data/billboard_result_20150103_20160430.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_date(week_from_one):\n",
    "    \n",
    "    day7 = timedelta(days=7)\n",
    "    day6 = timedelta(days=6)\n",
    "    date_slected = datetime.date(2016,1,3)\n",
    "    all_date =[date_slected]\n",
    "    all_date_last = [date_slected + day6]\n",
    "    for i in range(51):\n",
    "        date_slected = date_slected + day7\n",
    "        all_date.append(date_slected)\n",
    "        all_date_last.append(date_slected +day6)\n",
    "        \n",
    "        \n",
    "\n",
    "    week_Date = pd.DataFrame()\n",
    "    week_Date['firstData'] = all_date\n",
    "    week_Date['lastData'] = all_date_last\n",
    "    week_Date['week'] = range(1,53)\n",
    "    index_date = week_from_one - 1\n",
    "    \n",
    "    return str(all_date[index_date]) + ' ~ ' + str(all_date_last[index_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_no_twitter(list_id, db):\n",
    "    list_count = []\n",
    "    for song_id in list_id:\n",
    "        table_name = \"test_01_\" + str(song_id)\n",
    "        tab = db[table_name]\n",
    "        list_count.append(tab.find().count())\n",
    "    \n",
    "    return list(np.array(list_id)[np.array(list_count) == 0])\n",
    "\n",
    "db = client['song3_database']\n",
    "list_input = get_billboard(\"../data/billboard.csv\")\n",
    "list_id = range(len(list_input))    \n",
    "len(list_no_twitter(list_id, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_no_twitter2(list_id, db1, db2):\n",
    "    list1 = list_no_twitter(list_id, db1)\n",
    "    list2 = list_no_twitter(list_id, db2)\n",
    "    return list(set(list1).intersection(set(list2)))\n",
    "\n",
    "db1 = client['song3_database']\n",
    "db2 = client['song4_database']\n",
    "list_input = get_billboard(\"../data/billboard.csv\")\n",
    "list_id = range(len(list_input))   \n",
    "len(list_no_twitter2(list_id, db1,db2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twitter_info_table(song_id, db, list_input, current_billboard, week_all):\n",
    "\n",
    "    table_name = \"test_01_\" + str(song_id)\n",
    "    tab = db[table_name]\n",
    "    \n",
    "    Input = [ [\"#\"+str(id.split('%')[0]), str(id.split('%')[1])]  for id in list_input[\"ID\"]]\n",
    "    max_week = max([x for x in list(current_billboard.columns) if isinstance(x, int)])\n",
    "    current_billboard[max_week+1] = 0\n",
    "    Song_history = current_billboard[current_billboard['ID']==list_input['ID'].values[song_id]]\n",
    "\n",
    "    twit = info_twitter_song(tab)\n",
    "    twit['diff_time'] = twit['created_at_time_max'] - twit['created_at_time_min']\n",
    "    twit['diff_hour'] = twit['diff_time'].astype(pd.Timedelta).map(lambda x : float(x.seconds)/3600)\n",
    "    twit['diff_hour_adj'] = twit['diff_hour'].map(lambda x: 24*7 if x == 0 else x )\n",
    "    twit['twitter_per_hour'] = 1.0*twit['count']/twit['diff_hour_adj']\n",
    "    \n",
    "    \n",
    "    col = ['week_from_one', 'twitter_per_hour','pos_rate', 'neg_rate','ratio_pos_neg' ,'favorite_rate']\n",
    "    twitter_table = twit[col]\n",
    "    \n",
    "    diff = set(week_all) - set(list(twitter_table['week_from_one'].values))\n",
    "    \n",
    "    if len(diff) > 0:\n",
    "        for i in diff:\n",
    "            add_one = twitter_table.copy().iloc[0:1,]\n",
    "            add_one['week_from_one'] = i\n",
    "            add_one['twitter_per_hour'] = 1.0/(24*7)\n",
    "            add_one['pos_rate'] = 0\n",
    "            add_one['neg_rate'] = 0\n",
    "            add_one['ratio_pos_neg'] = 1\n",
    "            add_one['favorite_rate'] = 0\n",
    "            twitter_table = pd.concat([add_one, twitter_table])\n",
    "            \n",
    "    twitter_table['Billboard_rank'] = [int(Song_history[week]) for week in twitter_table['week_from_one']]\n",
    "    twitter_table['date_period'] = twitter_table['week_from_one'].map(find_date)\n",
    "    #twitter_table['Billboard_rank_text'] = twitter_table['Billboard_rank'].map(lambda x : x if x <= 100 else \"Not on Billboard\")\n",
    "    twitter_table['Song_ID'] = list_input[\"ID\"].values[song_id]\n",
    "    twitter_table['Song_IDN'] = song_id+1\n",
    "    \n",
    "    \n",
    "    return Song_history, twitter_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twitter_info_table2(song_id, db1, db2, list_input, current_billboard, week_all):\n",
    "\n",
    "    table_name = \"test_01_\" + str(song_id)\n",
    "    tab1 = db1[table_name]\n",
    "    tab2 = db2[table_name]\n",
    "    \n",
    "    Input = [ [\"#\"+str(id.split('%')[0]), str(id.split('%')[1])]  for id in list_input[\"ID\"]]\n",
    "    max_week = max([x for x in list(current_billboard.columns) if isinstance(x, int)])\n",
    "    current_billboard[max_week+1] = 0\n",
    "    Song_history = current_billboard[current_billboard['ID']==list_input['ID'].values[song_id]]\n",
    "\n",
    "    twit = info_twitter_song2(tab1, tab2)\n",
    "    twit['diff_time'] = twit['created_at_time_max'] - twit['created_at_time_min']\n",
    "    twit['diff_hour'] = twit['diff_time'].astype(pd.Timedelta).map(lambda x : float(x.seconds)/3600)\n",
    "    twit['diff_hour_adj'] = twit['diff_hour'].map(lambda x: 24*7 if x == 0 else x )\n",
    "    twit['twitter_per_hour'] = 1.0*twit['count']/twit['diff_hour_adj']\n",
    "    \n",
    "    \n",
    "    col = ['week_from_one', 'twitter_per_hour','pos_rate', 'neg_rate','ratio_pos_neg' ,'favorite_rate']\n",
    "    twitter_table = twit[col]\n",
    "    \n",
    "    diff = set(week_all) - set(list(twitter_table['week_from_one'].values))\n",
    "    \n",
    "    if len(diff) > 0:\n",
    "        for i in diff:\n",
    "            add_one = twitter_table.copy().iloc[0:1,]\n",
    "            add_one['week_from_one'] = i\n",
    "            add_one['twitter_per_hour'] = 1.0/(24*7)\n",
    "            add_one['pos_rate'] = 0\n",
    "            add_one['neg_rate'] = 0\n",
    "            add_one['ratio_pos_neg'] = 1\n",
    "            add_one['favorite_rate'] = 0\n",
    "            twitter_table = pd.concat([add_one, twitter_table])\n",
    "            \n",
    "    twitter_table['Billboard_rank'] = [int(Song_history[week]) for week in twitter_table['week_from_one']]\n",
    "    twitter_table['date_period'] = twitter_table['week_from_one'].map(find_date)\n",
    "    #twitter_table['Billboard_rank_text'] = twitter_table['Billboard_rank'].map(lambda x : x if x <= 100 else \"Not on Billboard\")\n",
    "    twitter_table['Song_ID'] = list_input[\"ID\"].values[song_id]\n",
    "    twitter_table['Song_IDN'] = song_id+1\n",
    "    \n",
    "    \n",
    "    return Song_history, twitter_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twitter_info_table_no_twitter(song_id, list_input, current_billboard, week_all):\n",
    "\n",
    "\n",
    "    Input = [ [\"#\"+str(id.split('%')[0]), str(id.split('%')[1])]  for id in list_input[\"ID\"]]\n",
    "    max_week = max([x for x in list(current_billboard.columns) if isinstance(x, int)])\n",
    "    current_billboard[max_week+1] = 0\n",
    "    \n",
    "    Song_history = current_billboard[current_billboard['ID']==list_input['ID'].values[song_id]]\n",
    "\n",
    "    \n",
    "    twitter_table = pd.DataFrame()\n",
    "    twitter_table['week_from_one'] = week_all\n",
    "    twitter_table['twitter_per_hour'] = 1.0/(24*7)\n",
    "    twitter_table['pos_rate'] = 0\n",
    "    twitter_table['neg_rate'] = 0\n",
    "    twitter_table['ratio_pos_neg'] = 1\n",
    "    twitter_table['favorite_rate'] = 0\n",
    "            \n",
    "    twitter_table['Billboard_rank'] = [int(Song_history[week]) for week in twitter_table['week_from_one']]\n",
    "    twitter_table['date_period'] = twitter_table['week_from_one'].map(find_date)\n",
    "    #twitter_table['Billboard_rank_text'] = twitter_table['Billboard_rank'].map(lambda x : x if x <= 100 else \"Not on Billboard\")\n",
    "    twitter_table['Song_ID'] = list_input[\"ID\"].values[song_id]\n",
    "    twitter_table['Song_IDN'] = song_id+1\n",
    "    \n",
    "    return Song_history, twitter_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_DataFrame_for_song(song_id, db, list_input, current_billboard, week_all):\n",
    "    \n",
    "    NoTwitter = list_no_twitter(range(len(list_input)), db)\n",
    "    \n",
    "    if song_id in NoTwitter:\n",
    "        Song_history, twitter_table = twitter_info_table_no_twitter(song_id, db, list_input, current_billboard, week_all)\n",
    "    else:\n",
    "        Song_history, twitter_table = twitter_info_table(song_id, db, list_input, current_billboard, week_all)\n",
    "    \n",
    "    df_song = twitter_table\n",
    "    df_song = df_song.rename(columns = {'week_from_one':'week'})\n",
    "    df_song = df_song.rename(columns = {'Billboard_rank':'current_rank'})\n",
    "    df_song['past_rank_1'] = df_song['week'].map(lambda x : int(Song_history[x-1]))\n",
    "    df_song['past_rank_2'] = df_song['week'].map(lambda x : int(Song_history[x-2]))\n",
    "    df_song['past_rank_3'] = df_song['week'].map(lambda x : int(Song_history[x-3]))\n",
    "    df_song['past_rank_4'] = df_song['week'].map(lambda x : int(Song_history[x-4]))\n",
    "    df_song['past_rank_5'] = df_song['week'].map(lambda x : int(Song_history[x-5]))\n",
    "    df_song['past_rank_6'] = df_song['week'].map(lambda x : int(Song_history[x-6]))\n",
    "    df_song['past_rank_7'] = df_song['week'].map(lambda x : int(Song_history[x-7]))\n",
    "    df_song['past_rank_8'] = df_song['week'].map(lambda x : int(Song_history[x-8]))\n",
    "    df_song['past_rank_9'] = df_song['week'].map(lambda x : int(Song_history[x-9]))\n",
    "    df_song['next_rank'] = df_song['week'].map(lambda x : int(Song_history[x+1]))                                     \n",
    "    \n",
    "    \n",
    "    col =['date_period','week','current_rank','count','twitter_per_hour','pos_rate',\\\n",
    "          'neg_rate','ratio_pos_neg','favorite_rate','Song_ID','Song_IDN',\\\n",
    "          'past_rank_1','past_rank_2','past_rank_3','past_rank_4','past_rank_5',\\\n",
    "          'past_rank_6','past_rank_7','past_rank_8','past_rank_9''next_rank']\n",
    "    \n",
    "    return df_song\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_DataFrame_for_song2(song_id, db1, db2, list_input, current_billboard, week_all):\n",
    "    \n",
    "    NoTwitter = list_no_twitter2(range(len(list_input)), db1, db2)\n",
    "    \n",
    "    if song_id in NoTwitter:\n",
    "        Song_history, twitter_table = twitter_info_table_no_twitter(song_id, list_input, current_billboard, week_all)\n",
    "    else:\n",
    "        Song_history, twitter_table = twitter_info_table2(song_id, db1, db2, list_input, current_billboard, week_all)\n",
    "    \n",
    "    df_song = twitter_table\n",
    "    df_song = df_song.rename(columns = {'week_from_one':'week'})\n",
    "    df_song = df_song.rename(columns = {'Billboard_rank':'current_rank'})\n",
    "    df_song['past_rank_1'] = df_song['week'].map(lambda x : int(Song_history[x-1]))\n",
    "    df_song['past_rank_2'] = df_song['week'].map(lambda x : int(Song_history[x-2]))\n",
    "    df_song['past_rank_3'] = df_song['week'].map(lambda x : int(Song_history[x-3]))\n",
    "    df_song['past_rank_4'] = df_song['week'].map(lambda x : int(Song_history[x-4]))\n",
    "    df_song['past_rank_5'] = df_song['week'].map(lambda x : int(Song_history[x-5]))\n",
    "    df_song['past_rank_6'] = df_song['week'].map(lambda x : int(Song_history[x-6]))\n",
    "    df_song['past_rank_7'] = df_song['week'].map(lambda x : int(Song_history[x-7]))\n",
    "    df_song['past_rank_8'] = df_song['week'].map(lambda x : int(Song_history[x-8]))\n",
    "    df_song['past_rank_9'] = df_song['week'].map(lambda x : int(Song_history[x-9]))\n",
    "    df_song['next_rank'] = df_song['week'].map(lambda x : int(Song_history[x+1]))                                     \n",
    "    \n",
    "    \n",
    "    col =['date_period','week','current_rank','count','twitter_per_hour','pos_rate',\\\n",
    "          'neg_rate','ratio_pos_neg','favorite_rate','Song_ID','Song_IDN',\\\n",
    "          'past_rank_1','past_rank_2','past_rank_3','past_rank_4','past_rank_5',\\\n",
    "          'past_rank_6','past_rank_7','past_rank_8','past_rank_9''next_rank']\n",
    "    \n",
    "    return df_song[col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dataframe(list_id, db, list_input, current_billboard, file_name, week_all=[]):\n",
    "    \n",
    "    print \"We are getting data frame for id = {}\".format(list_id[0])\n",
    "    df = get_DataFrame_for_song(list_id[0], db, list_input, current_billboard, week_all)    \n",
    "    print \"The length of dataFrame is {}.\".format(len(df))\n",
    "    print \" \"\n",
    "    \n",
    "    if len(list_id) == 1:\n",
    "        print \"We're done\"\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    for i in range(1, len(list_id)):\n",
    "        print \"We completed {} of the total work and now are merging the data frame with id = {}\".format\\\n",
    "        (1.0*i/len(list_id), list_id[i])\n",
    "        \n",
    "        add_df = get_DataFrame_for_song(list_id[i], db, list_input, current_billboard, week_all)\n",
    "        df = pd.concat([df, add_df])\n",
    "        print \"The length of dataFrame is {}.\".format(len(df))\n",
    "        print \" \"\n",
    "    \n",
    "    df.to_csv(file_name, sep=',', encoding='utf-8')\n",
    "    print \"We're done\"\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dataframe2(list_id, db1, db2, list_input, current_billboard, file_name, week_all=[]):\n",
    "    \n",
    "    print \"We are getting data frame for id = {}\".format(list_id[0])\n",
    "    df = get_DataFrame_for_song2(list_id[0], db1, db2, list_input, current_billboard, week_all)    \n",
    "    print \"The length of dataFrame is {}.\".format(len(df))\n",
    "    print \" \"\n",
    "    \n",
    "    if len(list_id) == 1:\n",
    "        print \"We're done\"\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    for i in range(1, len(list_id)):\n",
    "        print \"We completed {} of the total work and now are merging the data frame with id = {}\".format\\\n",
    "        (1.0*i/len(list_id), list_id[i])\n",
    "        \n",
    "        add_df = get_DataFrame_for_song2(list_id[i], db1, db2, list_input, current_billboard, week_all)\n",
    "        df = pd.concat([df, add_df])\n",
    "        print \"The length of dataFrame is {}.\".format(len(df))\n",
    "        print \" \"\n",
    "    \n",
    "    df.to_csv(file_name, sep=',', encoding='utf-8')\n",
    "    print \"We're done\"\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db1 = client['song3_database']\n",
    "db2 = client['song4_database']\n",
    "list_input = get_billboard(\"../data/billboard.csv\")\n",
    "current_billboard = get_billboard(\"../data/billboard3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>week_from_one</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>ID</th>\n",
       "      <th>...</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>$ave Dat Money%LIL DICKY</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>2 Phones%KEVIN GATES</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>679%FETTY WAP</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7 Years%LUKAS GRAHAM</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>Acquainted%THE WEEKND</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Adventure Of A Lifetime%COLDPLAY</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>Ain't Your Mama%JENNIFER LOPEZ</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>All I Ask%ADELE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>All The Way Up%FAT JOE &amp; REMY MA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>American Country Love Song%JAKE OWEN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Antidote%TRAVI$ SCOTT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>Back To Sleep%CHRIS BROWN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Backroad Song%GRANGER SMITH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Bang My Head%DAVID GUETTA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>43</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Be Alright%ARIANA GRANDE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>94</td>\n",
       "      <td>101</td>\n",
       "      <td>Beautiful Drug%ZAC BROWN BAND</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "      <td>Best Friend%YOUNG THUG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Bet You Can't Do It Like Me%DLOW</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>98</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>Body%DREEZY</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>66</td>\n",
       "      <td>54</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Break On Me.%KEITH URBAN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>47</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Break Up In A Small Town%SAM HUNT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>Cake By The Ocean%DNCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>54</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>Came Here To Forget%BLAKE SHELTON</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Can't Feel My Face%THE WEEKND</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "      <td>71</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>Cheap Thrills%SIA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>Close%NICK JONAS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>Come And See Me%PARTYNEXTDOOR</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>Company%JUSTIN BIEBER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>Confession%FLORIDA GEORGIA LINE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>75</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Confident%DEMI LOVATO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>T-Shirt%THOMAS RHETT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>42</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>Team%IGGY AZALEA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>101</td>\n",
       "      <td>Tennessee Whiskey%CHRIS STAPLETON</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>64</td>\n",
       "      <td>That Don't Sound Like You%LEE BRICE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>The Hills%THE WEEKND</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>101</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>The Sound Of Silence%DISTURBED</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>64</td>\n",
       "      <td>68</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>Think Of You%CHRIS YOUNG duet with CASSADEE POPE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Til It Happens To You%LADY GAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>Try Everything%SHAKIRA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>82</td>\n",
       "      <td>Uber Everywhere%MADEINTYO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "      <td>Ultralight Beam%KANYE WEST</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>79</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Untitled 02 I 06.23.2014.%KENDRICK LAMAR</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Untitled 07 I 2014-2016%KENDRICK LAMAR</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>22</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Uptown Funk!%MARK RONSON</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>Victorious%PANIC! AT THE DISCO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Walking On A Dream%EMPIRE OF THE SUN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>74</td>\n",
       "      <td>101</td>\n",
       "      <td>Wasted Time%KEITH URBAN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Watch Out%2 CHAINZ</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>71</td>\n",
       "      <td>86</td>\n",
       "      <td>Waves%KANYE WEST</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>We Went%RANDY HOUSER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>What Do You Mean?%JUSTIN BIEBER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>101</td>\n",
       "      <td>When We Were Young%ADELE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>White Iverson%POST MALONE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>101</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>Wild Things%ALESSIA CARA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Wildest Dreams%TAYLOR SWIFT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>87</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>With Them%YOUNG THUG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>Work From Home%FIFTH HARMONY</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Work%RIHANNA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>You Should Be Here%COLE SWINDELL</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "      <td>Youth%TROYE SIVAN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows  305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "week_from_one    9   10   11   12   13   14   15   16   17  \\\n",
       "1               95   95   89  101  101  101  101  101  101   \n",
       "2               40   29   25   21   18   18   18   17   18   \n",
       "3               34   30   35   39   40   39   40  101  101   \n",
       "4               20   12    9    5    3    2    2    2    3   \n",
       "5               82   76   75   77   76   73   70   77   72   \n",
       "6               28   33   41   53   65   76  101  101  101   \n",
       "7              101  101  101  101  101  101  101  101   92   \n",
       "8               77  101  101  101  101  101  101  101  101   \n",
       "9              101  101  101  101  101  101   91   81   69   \n",
       "10             101  101  101   83  101  101  101  101  101   \n",
       "11              36   40   47  101  101  101  101  101  101   \n",
       "12              50   36   20   25   29   30   37   44   37   \n",
       "13              57   60   71   65   89   94  101  101  101   \n",
       "14              93  101  101  101  101  101  101  101  101   \n",
       "15             101  101  101  101  101   43  101  101  101   \n",
       "16              64   59   57   55   52   72   76   94  101   \n",
       "17              51   48   51   56   57   65   66   76  101   \n",
       "18              97  101  101  101  101  101  101  101  101   \n",
       "19             101  101  101  101  101   98   89   88   77   \n",
       "20              66   54   65   81   99  101  101  101  101   \n",
       "21              47  101  101  101  101  101  101  101  101   \n",
       "22              10    9   10    9    9    9   11   12    9   \n",
       "23             101  101  101   54   42   61   48   40   48   \n",
       "24              32   38   39   45   50  101  101  101  101   \n",
       "25              81   97   91   92   87   71   39   55   47   \n",
       "26             101  101  101  101  101  101   27   33   29   \n",
       "27             101  101  101  101  101  101  101   97   98   \n",
       "28             101  101  101   89   77   66   57   57   53   \n",
       "29              69   62   62   60   60   55   56   53   55   \n",
       "30              75  101  101  101  101  101  101  101  101   \n",
       "..             ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "140            101  101   92   84   80   74   63   63   61   \n",
       "141            101  101  101  101  101   42   71   65   59   \n",
       "142            101  101  101  101  101  101  101   90  101   \n",
       "143             98   92   88   93   92   90   64   69   64   \n",
       "144             27   22   21   24   25   28   33   42   39   \n",
       "145            101   88   81   76   73   69   51   49   42   \n",
       "146             86   74   69   64   68   57   53   41   40   \n",
       "147            101  101   95  101  101  101  101  101  101   \n",
       "148            101  101  101   66   63   86   65   75   74   \n",
       "149            101  101  101  101  101  101   99  101   82   \n",
       "150            101  101  101  101  101  101  101   67   90   \n",
       "151            101  101  101   79  101  101  101  101  101   \n",
       "152            101  101  101   90  101  101  101  101  101   \n",
       "153             22  101  101  101  101  101  101  101  101   \n",
       "154            101  101  101  101  101  101   94   96   96   \n",
       "155            101   90   99  101  101  101  101  101  101   \n",
       "156            101  101  101  101  101  101  101   74  101   \n",
       "157             91   89   98   91  101  101  101  101  101   \n",
       "158            101  101  101  101  101  101  101   71   86   \n",
       "159             71   63   60   75   91  101  101  101  101   \n",
       "160             25   25   29   34   36   37   41  101  101   \n",
       "161             14   18   23   28   34   50   58   70  101   \n",
       "162             39   42   44   46   49   45   49  101  101   \n",
       "163            101   91   80   69   66   58   60   60   56   \n",
       "164             46   46  101  101  101  101  101  101  101   \n",
       "165            101  101  101  101  101  101   87  101  101   \n",
       "166            101  101   12   16   13   12   10    9    7   \n",
       "167              1    1    1    1    1    1    1    1    1   \n",
       "168             55   50   43   38   32   32   31   35   38   \n",
       "169             80   67   58   58   23   36   34   46   43   \n",
       "\n",
       "week_from_one                                                ID ...  300 301  \\\n",
       "1                                     $ave Dat Money%LIL DICKY  ...    0   0   \n",
       "2                                          2 Phones%KEVIN GATES ...    0   0   \n",
       "3                                                679%FETTY WAP  ...    0   0   \n",
       "4                                          7 Years%LUKAS GRAHAM ...    0   0   \n",
       "5                                         Acquainted%THE WEEKND ...    0   0   \n",
       "6                              Adventure Of A Lifetime%COLDPLAY ...    0   0   \n",
       "7                                Ain't Your Mama%JENNIFER LOPEZ ...    0   0   \n",
       "8                                               All I Ask%ADELE ...    0   0   \n",
       "9                             All The Way Up%FAT JOE & REMY MA  ...    0   0   \n",
       "10                         American Country Love Song%JAKE OWEN ...    0   0   \n",
       "11                                        Antidote%TRAVI$ SCOTT ...    0   0   \n",
       "12                                    Back To Sleep%CHRIS BROWN ...    0   0   \n",
       "13                                  Backroad Song%GRANGER SMITH ...    0   0   \n",
       "14                                   Bang My Head%DAVID GUETTA  ...    0   0   \n",
       "15                                     Be Alright%ARIANA GRANDE ...    0   0   \n",
       "16                                Beautiful Drug%ZAC BROWN BAND ...    0   0   \n",
       "17                                       Best Friend%YOUNG THUG ...    0   0   \n",
       "18                             Bet You Can't Do It Like Me%DLOW ...    0   0   \n",
       "19                                                 Body%DREEZY  ...    0   0   \n",
       "20                                     Break On Me.%KEITH URBAN ...    0   0   \n",
       "21                            Break Up In A Small Town%SAM HUNT ...    0   0   \n",
       "22                                       Cake By The Ocean%DNCE ...    0   0   \n",
       "23                            Came Here To Forget%BLAKE SHELTON ...    0   0   \n",
       "24                                Can't Feel My Face%THE WEEKND ...    0   0   \n",
       "25                                           Cheap Thrills%SIA  ...    0   0   \n",
       "26                                            Close%NICK JONAS  ...    0   0   \n",
       "27                               Come And See Me%PARTYNEXTDOOR  ...    0   0   \n",
       "28                                        Company%JUSTIN BIEBER ...    0   0   \n",
       "29                              Confession%FLORIDA GEORGIA LINE ...    0   0   \n",
       "30                                        Confident%DEMI LOVATO ...    0   0   \n",
       "..                                                          ... ...   ..  ..   \n",
       "140                                        T-Shirt%THOMAS RHETT ...    0   0   \n",
       "141                                            Team%IGGY AZALEA ...    0   0   \n",
       "142                           Tennessee Whiskey%CHRIS STAPLETON ...    0   0   \n",
       "143                         That Don't Sound Like You%LEE BRICE ...    0   0   \n",
       "144                                        The Hills%THE WEEKND ...    0   0   \n",
       "145                              The Sound Of Silence%DISTURBED ...    0   0   \n",
       "146            Think Of You%CHRIS YOUNG duet with CASSADEE POPE ...    0   0   \n",
       "147                             Til It Happens To You%LADY GAGA ...    0   0   \n",
       "148                                      Try Everything%SHAKIRA ...    0   0   \n",
       "149                                   Uber Everywhere%MADEINTYO ...    0   0   \n",
       "150                                  Ultralight Beam%KANYE WEST ...    0   0   \n",
       "151                    Untitled 02 I 06.23.2014.%KENDRICK LAMAR ...    0   0   \n",
       "152                      Untitled 07 I 2014-2016%KENDRICK LAMAR ...    0   0   \n",
       "153                                   Uptown Funk!%MARK RONSON  ...    0   0   \n",
       "154                              Victorious%PANIC! AT THE DISCO ...    0   0   \n",
       "155                        Walking On A Dream%EMPIRE OF THE SUN ...    0   0   \n",
       "156                                     Wasted Time%KEITH URBAN ...    0   0   \n",
       "157                                          Watch Out%2 CHAINZ ...    0   0   \n",
       "158                                            Waves%KANYE WEST ...    0   0   \n",
       "159                                        We Went%RANDY HOUSER ...    0   0   \n",
       "160                             What Do You Mean?%JUSTIN BIEBER ...    0   0   \n",
       "161                                    When We Were Young%ADELE ...    0   0   \n",
       "162                                   White Iverson%POST MALONE ...    0   0   \n",
       "163                                    Wild Things%ALESSIA CARA ...    0   0   \n",
       "164                                 Wildest Dreams%TAYLOR SWIFT ...    0   0   \n",
       "165                                        With Them%YOUNG THUG ...    0   0   \n",
       "166                               Work From Home%FIFTH HARMONY  ...    0   0   \n",
       "167                                               Work%RIHANNA  ...    0   0   \n",
       "168                            You Should Be Here%COLE SWINDELL ...    0   0   \n",
       "169                                           Youth%TROYE SIVAN ...    0   0   \n",
       "\n",
       "week_from_one  302  303  304  305  306  307  308  309  \n",
       "1                0    0    0    0    0    0    0    0  \n",
       "2                0    0    0    0    0    0    0    0  \n",
       "3                0    0    0    0    0    0    0    0  \n",
       "4                0    0    0    0    0    0    0    0  \n",
       "5                0    0    0    0    0    0    0    0  \n",
       "6                0    0    0    0    0    0    0    0  \n",
       "7                0    0    0    0    0    0    0    0  \n",
       "8                0    0    0    0    0    0    0    0  \n",
       "9                0    0    0    0    0    0    0    0  \n",
       "10               0    0    0    0    0    0    0    0  \n",
       "11               0    0    0    0    0    0    0    0  \n",
       "12               0    0    0    0    0    0    0    0  \n",
       "13               0    0    0    0    0    0    0    0  \n",
       "14               0    0    0    0    0    0    0    0  \n",
       "15               0    0    0    0    0    0    0    0  \n",
       "16               0    0    0    0    0    0    0    0  \n",
       "17               0    0    0    0    0    0    0    0  \n",
       "18               0    0    0    0    0    0    0    0  \n",
       "19               0    0    0    0    0    0    0    0  \n",
       "20               0    0    0    0    0    0    0    0  \n",
       "21               0    0    0    0    0    0    0    0  \n",
       "22               0    0    0    0    0    0    0    0  \n",
       "23               0    0    0    0    0    0    0    0  \n",
       "24               0    0    0    0    0    0    0    0  \n",
       "25               0    0    0    0    0    0    0    0  \n",
       "26               0    0    0    0    0    0    0    0  \n",
       "27               0    0    0    0    0    0    0    0  \n",
       "28               0    0    0    0    0    0    0    0  \n",
       "29               0    0    0    0    0    0    0    0  \n",
       "30               0    0    0    0    0    0    0    0  \n",
       "..             ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "140              0    0    0    0    0    0    0    0  \n",
       "141              0    0    0    0    0    0    0    0  \n",
       "142              0    0    0    0    0    0    0    0  \n",
       "143              0    0    0    0    0    0    0    0  \n",
       "144              0    0    0    0    0    0    0    0  \n",
       "145              0    0    0    0    0    0    0    0  \n",
       "146              0    0    0    0    0    0    0    0  \n",
       "147              0    0    0    0    0    0    0    0  \n",
       "148              0    0    0    0    0    0    0    0  \n",
       "149              0    0    0    0    0    0    0    0  \n",
       "150              0    0    0    0    0    0    0    0  \n",
       "151              0    0    0    0    0    0    0    0  \n",
       "152              0    0    0    0    0    0    0    0  \n",
       "153              0    0    0    0    0    0    0    0  \n",
       "154              0    0    0    0    0    0    0    0  \n",
       "155              0    0    0    0    0    0    0    0  \n",
       "156              0    0    0    0    0    0    0    0  \n",
       "157              0    0    0    0    0    0    0    0  \n",
       "158              0    0    0    0    0    0    0    0  \n",
       "159              0    0    0    0    0    0    0    0  \n",
       "160              0    0    0    0    0    0    0    0  \n",
       "161              0    0    0    0    0    0    0    0  \n",
       "162              0    0    0    0    0    0    0    0  \n",
       "163              0    0    0    0    0    0    0    0  \n",
       "164              0    0    0    0    0    0    0    0  \n",
       "165              0    0    0    0    0    0    0    0  \n",
       "166              0    0    0    0    0    0    0    0  \n",
       "167              0    0    0    0    0    0    0    0  \n",
       "168              0    0    0    0    0    0    0    0  \n",
       "169              0    0    0    0    0    0    0    0  \n",
       "\n",
       "[169 rows x 305 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are getting data frame for id = 0\n",
      "The length of dataFrame is 3.\n",
      " \n",
      "We completed 0.00684931506849 of the total work and now are merging the data frame with id = 1\n",
      "The length of dataFrame is 6.\n",
      " \n",
      "We completed 0.013698630137 of the total work and now are merging the data frame with id = 2\n",
      "The length of dataFrame is 9.\n",
      " \n",
      "We completed 0.0205479452055 of the total work and now are merging the data frame with id = 3\n",
      "The length of dataFrame is 12.\n",
      " \n",
      "We completed 0.027397260274 of the total work and now are merging the data frame with id = 4\n",
      "The length of dataFrame is 15.\n",
      " \n",
      "We completed 0.0342465753425 of the total work and now are merging the data frame with id = 5\n",
      "The length of dataFrame is 18.\n",
      " \n",
      "We completed 0.041095890411 of the total work and now are merging the data frame with id = 6\n",
      "The length of dataFrame is 21.\n",
      " \n",
      "We completed 0.0479452054795 of the total work and now are merging the data frame with id = 7\n",
      "The length of dataFrame is 24.\n",
      " \n",
      "We completed 0.0547945205479 of the total work and now are merging the data frame with id = 8\n",
      "The length of dataFrame is 27.\n",
      " \n",
      "We completed 0.0616438356164 of the total work and now are merging the data frame with id = 9\n",
      "The length of dataFrame is 30.\n",
      " \n",
      "We completed 0.0684931506849 of the total work and now are merging the data frame with id = 10\n",
      "The length of dataFrame is 33.\n",
      " \n",
      "We completed 0.0753424657534 of the total work and now are merging the data frame with id = 11\n",
      "The length of dataFrame is 36.\n",
      " \n",
      "We completed 0.0821917808219 of the total work and now are merging the data frame with id = 12\n",
      "The length of dataFrame is 39.\n",
      " \n",
      "We completed 0.0890410958904 of the total work and now are merging the data frame with id = 13\n",
      "The length of dataFrame is 42.\n",
      " \n",
      "We completed 0.0958904109589 of the total work and now are merging the data frame with id = 14\n",
      "The length of dataFrame is 45.\n",
      " \n",
      "We completed 0.102739726027 of the total work and now are merging the data frame with id = 15\n",
      "The length of dataFrame is 48.\n",
      " \n",
      "We completed 0.109589041096 of the total work and now are merging the data frame with id = 16\n",
      "The length of dataFrame is 51.\n",
      " \n",
      "We completed 0.116438356164 of the total work and now are merging the data frame with id = 17\n",
      "The length of dataFrame is 54.\n",
      " \n",
      "We completed 0.123287671233 of the total work and now are merging the data frame with id = 18\n",
      "The length of dataFrame is 57.\n",
      " \n",
      "We completed 0.130136986301 of the total work and now are merging the data frame with id = 19\n",
      "The length of dataFrame is 60.\n",
      " \n",
      "We completed 0.13698630137 of the total work and now are merging the data frame with id = 20\n",
      "The length of dataFrame is 63.\n",
      " \n",
      "We completed 0.143835616438 of the total work and now are merging the data frame with id = 21\n",
      "The length of dataFrame is 66.\n",
      " \n",
      "We completed 0.150684931507 of the total work and now are merging the data frame with id = 22\n",
      "The length of dataFrame is 69.\n",
      " \n",
      "We completed 0.157534246575 of the total work and now are merging the data frame with id = 23\n",
      "The length of dataFrame is 72.\n",
      " \n",
      "We completed 0.164383561644 of the total work and now are merging the data frame with id = 24\n",
      "The length of dataFrame is 75.\n",
      " \n",
      "We completed 0.171232876712 of the total work and now are merging the data frame with id = 25\n",
      "The length of dataFrame is 78.\n",
      " \n",
      "We completed 0.178082191781 of the total work and now are merging the data frame with id = 26\n",
      "The length of dataFrame is 81.\n",
      " \n",
      "We completed 0.184931506849 of the total work and now are merging the data frame with id = 27\n",
      "The length of dataFrame is 84.\n",
      " \n",
      "We completed 0.191780821918 of the total work and now are merging the data frame with id = 28\n",
      "The length of dataFrame is 87.\n",
      " \n",
      "We completed 0.198630136986 of the total work and now are merging the data frame with id = 29\n",
      "The length of dataFrame is 90.\n",
      " \n",
      "We completed 0.205479452055 of the total work and now are merging the data frame with id = 30\n",
      "The length of dataFrame is 93.\n",
      " \n",
      "We completed 0.212328767123 of the total work and now are merging the data frame with id = 31\n",
      "The length of dataFrame is 96.\n",
      " \n",
      "We completed 0.219178082192 of the total work and now are merging the data frame with id = 32\n",
      "The length of dataFrame is 99.\n",
      " \n",
      "We completed 0.22602739726 of the total work and now are merging the data frame with id = 33\n",
      "The length of dataFrame is 102.\n",
      " \n",
      "We completed 0.232876712329 of the total work and now are merging the data frame with id = 34\n",
      "The length of dataFrame is 105.\n",
      " \n",
      "We completed 0.239726027397 of the total work and now are merging the data frame with id = 35\n",
      "The length of dataFrame is 108.\n",
      " \n",
      "We completed 0.246575342466 of the total work and now are merging the data frame with id = 36\n",
      "The length of dataFrame is 111.\n",
      " \n",
      "We completed 0.253424657534 of the total work and now are merging the data frame with id = 37\n",
      "The length of dataFrame is 114.\n",
      " \n",
      "We completed 0.260273972603 of the total work and now are merging the data frame with id = 38\n",
      "The length of dataFrame is 117.\n",
      " \n",
      "We completed 0.267123287671 of the total work and now are merging the data frame with id = 39\n",
      "The length of dataFrame is 120.\n",
      " \n",
      "We completed 0.27397260274 of the total work and now are merging the data frame with id = 40\n",
      "The length of dataFrame is 123.\n",
      " \n",
      "We completed 0.280821917808 of the total work and now are merging the data frame with id = 41\n",
      "The length of dataFrame is 126.\n",
      " \n",
      "We completed 0.287671232877 of the total work and now are merging the data frame with id = 42\n",
      "The length of dataFrame is 129.\n",
      " \n",
      "We completed 0.294520547945 of the total work and now are merging the data frame with id = 43\n",
      "The length of dataFrame is 132.\n",
      " \n",
      "We completed 0.301369863014 of the total work and now are merging the data frame with id = 44\n",
      "The length of dataFrame is 135.\n",
      " \n",
      "We completed 0.308219178082 of the total work and now are merging the data frame with id = 45\n",
      "The length of dataFrame is 138.\n",
      " \n",
      "We completed 0.315068493151 of the total work and now are merging the data frame with id = 46\n",
      "The length of dataFrame is 141.\n",
      " \n",
      "We completed 0.321917808219 of the total work and now are merging the data frame with id = 47\n",
      "The length of dataFrame is 144.\n",
      " \n",
      "We completed 0.328767123288 of the total work and now are merging the data frame with id = 48\n",
      "The length of dataFrame is 147.\n",
      " \n",
      "We completed 0.335616438356 of the total work and now are merging the data frame with id = 49\n",
      "The length of dataFrame is 150.\n",
      " \n",
      "We completed 0.342465753425 of the total work and now are merging the data frame with id = 50\n",
      "The length of dataFrame is 153.\n",
      " \n",
      "We completed 0.349315068493 of the total work and now are merging the data frame with id = 51\n",
      "The length of dataFrame is 156.\n",
      " \n",
      "We completed 0.356164383562 of the total work and now are merging the data frame with id = 52\n",
      "The length of dataFrame is 159.\n",
      " \n",
      "We completed 0.36301369863 of the total work and now are merging the data frame with id = 53\n",
      "The length of dataFrame is 162.\n",
      " \n",
      "We completed 0.369863013699 of the total work and now are merging the data frame with id = 54\n",
      "The length of dataFrame is 165.\n",
      " \n",
      "We completed 0.376712328767 of the total work and now are merging the data frame with id = 55\n",
      "The length of dataFrame is 168.\n",
      " \n",
      "We completed 0.383561643836 of the total work and now are merging the data frame with id = 56\n",
      "The length of dataFrame is 171.\n",
      " \n",
      "We completed 0.390410958904 of the total work and now are merging the data frame with id = 57\n",
      "The length of dataFrame is 174.\n",
      " \n",
      "We completed 0.397260273973 of the total work and now are merging the data frame with id = 58\n",
      "The length of dataFrame is 177.\n",
      " \n",
      "We completed 0.404109589041 of the total work and now are merging the data frame with id = 59\n",
      "The length of dataFrame is 180.\n",
      " \n",
      "We completed 0.41095890411 of the total work and now are merging the data frame with id = 60\n",
      "The length of dataFrame is 183.\n",
      " \n",
      "We completed 0.417808219178 of the total work and now are merging the data frame with id = 61\n",
      "The length of dataFrame is 186.\n",
      " \n",
      "We completed 0.424657534247 of the total work and now are merging the data frame with id = 62\n",
      "The length of dataFrame is 189.\n",
      " \n",
      "We completed 0.431506849315 of the total work and now are merging the data frame with id = 63\n",
      "The length of dataFrame is 192.\n",
      " \n",
      "We completed 0.438356164384 of the total work and now are merging the data frame with id = 64\n",
      "The length of dataFrame is 195.\n",
      " \n",
      "We completed 0.445205479452 of the total work and now are merging the data frame with id = 65\n",
      "The length of dataFrame is 198.\n",
      " \n",
      "We completed 0.452054794521 of the total work and now are merging the data frame with id = 66\n",
      "The length of dataFrame is 201.\n",
      " \n",
      "We completed 0.458904109589 of the total work and now are merging the data frame with id = 67\n",
      "The length of dataFrame is 204.\n",
      " \n",
      "We completed 0.465753424658 of the total work and now are merging the data frame with id = 68\n",
      "The length of dataFrame is 207.\n",
      " \n",
      "We completed 0.472602739726 of the total work and now are merging the data frame with id = 69\n",
      "The length of dataFrame is 210.\n",
      " \n",
      "We completed 0.479452054795 of the total work and now are merging the data frame with id = 70\n",
      "The length of dataFrame is 213.\n",
      " \n",
      "We completed 0.486301369863 of the total work and now are merging the data frame with id = 71\n",
      "The length of dataFrame is 216.\n",
      " \n",
      "We completed 0.493150684932 of the total work and now are merging the data frame with id = 72\n",
      "The length of dataFrame is 219.\n",
      " \n",
      "We completed 0.5 of the total work and now are merging the data frame with id = 73\n",
      "The length of dataFrame is 222.\n",
      " \n",
      "We completed 0.506849315068 of the total work and now are merging the data frame with id = 74\n",
      "The length of dataFrame is 225.\n",
      " \n",
      "We completed 0.513698630137 of the total work and now are merging the data frame with id = 75\n",
      "The length of dataFrame is 228.\n",
      " \n",
      "We completed 0.520547945205 of the total work and now are merging the data frame with id = 76\n",
      "The length of dataFrame is 231.\n",
      " \n",
      "We completed 0.527397260274 of the total work and now are merging the data frame with id = 77\n",
      "The length of dataFrame is 234.\n",
      " \n",
      "We completed 0.534246575342 of the total work and now are merging the data frame with id = 78\n",
      "The length of dataFrame is 237.\n",
      " \n",
      "We completed 0.541095890411 of the total work and now are merging the data frame with id = 79\n",
      "The length of dataFrame is 240.\n",
      " \n",
      "We completed 0.547945205479 of the total work and now are merging the data frame with id = 80\n",
      "The length of dataFrame is 243.\n",
      " \n",
      "We completed 0.554794520548 of the total work and now are merging the data frame with id = 81\n",
      "The length of dataFrame is 246.\n",
      " \n",
      "We completed 0.561643835616 of the total work and now are merging the data frame with id = 82\n",
      "The length of dataFrame is 249.\n",
      " \n",
      "We completed 0.568493150685 of the total work and now are merging the data frame with id = 83\n",
      "The length of dataFrame is 252.\n",
      " \n",
      "We completed 0.575342465753 of the total work and now are merging the data frame with id = 84\n",
      "The length of dataFrame is 255.\n",
      " \n",
      "We completed 0.582191780822 of the total work and now are merging the data frame with id = 85\n",
      "The length of dataFrame is 258.\n",
      " \n",
      "We completed 0.58904109589 of the total work and now are merging the data frame with id = 86\n",
      "The length of dataFrame is 261.\n",
      " \n",
      "We completed 0.595890410959 of the total work and now are merging the data frame with id = 87\n",
      "The length of dataFrame is 264.\n",
      " \n",
      "We completed 0.602739726027 of the total work and now are merging the data frame with id = 88\n",
      "The length of dataFrame is 267.\n",
      " \n",
      "We completed 0.609589041096 of the total work and now are merging the data frame with id = 89\n",
      "The length of dataFrame is 270.\n",
      " \n",
      "We completed 0.616438356164 of the total work and now are merging the data frame with id = 90\n",
      "The length of dataFrame is 273.\n",
      " \n",
      "We completed 0.623287671233 of the total work and now are merging the data frame with id = 91\n",
      "The length of dataFrame is 276.\n",
      " \n",
      "We completed 0.630136986301 of the total work and now are merging the data frame with id = 92\n",
      "The length of dataFrame is 279.\n",
      " \n",
      "We completed 0.63698630137 of the total work and now are merging the data frame with id = 93\n",
      "The length of dataFrame is 282.\n",
      " \n",
      "We completed 0.643835616438 of the total work and now are merging the data frame with id = 94\n",
      "The length of dataFrame is 285.\n",
      " \n",
      "We completed 0.650684931507 of the total work and now are merging the data frame with id = 95\n",
      "The length of dataFrame is 288.\n",
      " \n",
      "We completed 0.657534246575 of the total work and now are merging the data frame with id = 96\n",
      "The length of dataFrame is 291.\n",
      " \n",
      "We completed 0.664383561644 of the total work and now are merging the data frame with id = 97\n",
      "The length of dataFrame is 294.\n",
      " \n",
      "We completed 0.671232876712 of the total work and now are merging the data frame with id = 98\n",
      "The length of dataFrame is 297.\n",
      " \n",
      "We completed 0.678082191781 of the total work and now are merging the data frame with id = 99\n",
      "The length of dataFrame is 300.\n",
      " \n",
      "We completed 0.684931506849 of the total work and now are merging the data frame with id = 100\n",
      "The length of dataFrame is 303.\n",
      " \n",
      "We completed 0.691780821918 of the total work and now are merging the data frame with id = 101\n",
      "The length of dataFrame is 306.\n",
      " \n",
      "We completed 0.698630136986 of the total work and now are merging the data frame with id = 102\n",
      "The length of dataFrame is 309.\n",
      " \n",
      "We completed 0.705479452055 of the total work and now are merging the data frame with id = 103\n",
      "The length of dataFrame is 312.\n",
      " \n",
      "We completed 0.712328767123 of the total work and now are merging the data frame with id = 104\n",
      "The length of dataFrame is 315.\n",
      " \n",
      "We completed 0.719178082192 of the total work and now are merging the data frame with id = 105\n",
      "The length of dataFrame is 318.\n",
      " \n",
      "We completed 0.72602739726 of the total work and now are merging the data frame with id = 106\n",
      "The length of dataFrame is 321.\n",
      " \n",
      "We completed 0.732876712329 of the total work and now are merging the data frame with id = 107\n",
      "The length of dataFrame is 324.\n",
      " \n",
      "We completed 0.739726027397 of the total work and now are merging the data frame with id = 108\n",
      "The length of dataFrame is 327.\n",
      " \n",
      "We completed 0.746575342466 of the total work and now are merging the data frame with id = 109\n",
      "The length of dataFrame is 330.\n",
      " \n",
      "We completed 0.753424657534 of the total work and now are merging the data frame with id = 110\n",
      "The length of dataFrame is 333.\n",
      " \n",
      "We completed 0.760273972603 of the total work and now are merging the data frame with id = 111\n",
      "The length of dataFrame is 336.\n",
      " \n",
      "We completed 0.767123287671 of the total work and now are merging the data frame with id = 112\n",
      "The length of dataFrame is 339.\n",
      " \n",
      "We completed 0.77397260274 of the total work and now are merging the data frame with id = 113\n",
      "The length of dataFrame is 342.\n",
      " \n",
      "We completed 0.780821917808 of the total work and now are merging the data frame with id = 114\n",
      "The length of dataFrame is 345.\n",
      " \n",
      "We completed 0.787671232877 of the total work and now are merging the data frame with id = 115\n",
      "The length of dataFrame is 348.\n",
      " \n",
      "We completed 0.794520547945 of the total work and now are merging the data frame with id = 116\n",
      "The length of dataFrame is 351.\n",
      " \n",
      "We completed 0.801369863014 of the total work and now are merging the data frame with id = 117\n",
      "The length of dataFrame is 354.\n",
      " \n",
      "We completed 0.808219178082 of the total work and now are merging the data frame with id = 118\n",
      "The length of dataFrame is 357.\n",
      " \n",
      "We completed 0.815068493151 of the total work and now are merging the data frame with id = 119\n",
      "The length of dataFrame is 360.\n",
      " \n",
      "We completed 0.821917808219 of the total work and now are merging the data frame with id = 120\n",
      "The length of dataFrame is 363.\n",
      " \n",
      "We completed 0.828767123288 of the total work and now are merging the data frame with id = 121\n",
      "The length of dataFrame is 366.\n",
      " \n",
      "We completed 0.835616438356 of the total work and now are merging the data frame with id = 122\n",
      "The length of dataFrame is 369.\n",
      " \n",
      "We completed 0.842465753425 of the total work and now are merging the data frame with id = 123\n",
      "The length of dataFrame is 372.\n",
      " \n",
      "We completed 0.849315068493 of the total work and now are merging the data frame with id = 124\n",
      "The length of dataFrame is 375.\n",
      " \n",
      "We completed 0.856164383562 of the total work and now are merging the data frame with id = 125\n",
      "The length of dataFrame is 378.\n",
      " \n",
      "We completed 0.86301369863 of the total work and now are merging the data frame with id = 126\n",
      "The length of dataFrame is 381.\n",
      " \n",
      "We completed 0.869863013699 of the total work and now are merging the data frame with id = 127\n",
      "The length of dataFrame is 384.\n",
      " \n",
      "We completed 0.876712328767 of the total work and now are merging the data frame with id = 128\n",
      "The length of dataFrame is 387.\n",
      " \n",
      "We completed 0.883561643836 of the total work and now are merging the data frame with id = 129\n",
      "The length of dataFrame is 390.\n",
      " \n",
      "We completed 0.890410958904 of the total work and now are merging the data frame with id = 130\n",
      "The length of dataFrame is 393.\n",
      " \n",
      "We completed 0.897260273973 of the total work and now are merging the data frame with id = 131\n",
      "The length of dataFrame is 396.\n",
      " \n",
      "We completed 0.904109589041 of the total work and now are merging the data frame with id = 132\n",
      "The length of dataFrame is 399.\n",
      " \n",
      "We completed 0.91095890411 of the total work and now are merging the data frame with id = 133\n",
      "The length of dataFrame is 402.\n",
      " \n",
      "We completed 0.917808219178 of the total work and now are merging the data frame with id = 134\n",
      "The length of dataFrame is 405.\n",
      " \n",
      "We completed 0.924657534247 of the total work and now are merging the data frame with id = 135\n",
      "The length of dataFrame is 408.\n",
      " \n",
      "We completed 0.931506849315 of the total work and now are merging the data frame with id = 136\n",
      "The length of dataFrame is 411.\n",
      " \n",
      "We completed 0.938356164384 of the total work and now are merging the data frame with id = 137\n",
      "The length of dataFrame is 414.\n",
      " \n",
      "We completed 0.945205479452 of the total work and now are merging the data frame with id = 138\n",
      "The length of dataFrame is 417.\n",
      " \n",
      "We completed 0.952054794521 of the total work and now are merging the data frame with id = 139\n",
      "The length of dataFrame is 420.\n",
      " \n",
      "We completed 0.958904109589 of the total work and now are merging the data frame with id = 140\n",
      "The length of dataFrame is 423.\n",
      " \n",
      "We completed 0.965753424658 of the total work and now are merging the data frame with id = 141\n",
      "The length of dataFrame is 426.\n",
      " \n",
      "We completed 0.972602739726 of the total work and now are merging the data frame with id = 142\n",
      "The length of dataFrame is 429.\n",
      " \n",
      "We completed 0.979452054795 of the total work and now are merging the data frame with id = 143\n",
      "The length of dataFrame is 433.\n",
      " \n",
      "We completed 0.986301369863 of the total work and now are merging the data frame with id = 144\n",
      "The length of dataFrame is 436.\n",
      " \n",
      "We completed 0.993150684932 of the total work and now are merging the data frame with id = 145\n",
      "The length of dataFrame is 440.\n",
      " \n",
      "We're done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "list_id = range(len(list_input))\n",
    "week_14_16 = [14,15,16]\n",
    "file_name = '../data/result_song_3_4_9_01.csv' \n",
    "df_total = merge_dataframe2(list_id, db1, db2, list_input, current_billboard, file_name, week_all=week_14_16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are getting data frame for id = 0\n",
      "The length of dataFrame is 3.\n",
      " \n",
      "We completed 0.5 of the total work and now are merging the data frame with id = 1\n",
      "The length of dataFrame is 6.\n",
      " \n",
      "We're done\n"
     ]
    }
   ],
   "source": [
    "list_id = range(2)\n",
    "week_14_16 = [14,15,16]\n",
    "file_name = '../data/result_song_3_4_9_01_test.csv' \n",
    "aaa=  merge_dataframe2(list_id, db1, db2, list_input, current_billboard, file_name, week_all=week_14_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5e2b2ecef66b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_DataFrame_for_song2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_billboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweek_14_16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maaa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-429fe35fe28e>\u001b[0m in \u001b[0;36mget_DataFrame_for_song2\u001b[0;34m(song_id, db1, db2, list_input, current_billboard, week_all)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_4'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_5'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_6'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_7'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_8'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2052\u001b[0m                                      index=self.index).__finalize__(self)\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m             return self._constructor(mapped,\n\u001b[1;32m   2056\u001b[0m                                      index=self.index).__finalize__(self)\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62578)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-429fe35fe28e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_4'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_5'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_6'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_7'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_rank_8'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSong_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yeongcheon/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 8"
     ]
    }
   ],
   "source": [
    "aaa = get_DataFrame_for_song2(0, db1, db2, list_input, current_billboard, week_14_16)\n",
    "aaa.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_raw_dataframe2(list_id, db1, db2, file_name):\n",
    "    \n",
    "    print \"We are getting data frame for id = {}\".format(list_id[0])\n",
    "    table_name = \"test_01_\" + str(list_id[0])\n",
    "    tab1 = db1[table_name]\n",
    "    tab2 = db2[table_name]\n",
    "    df = info_raw_twitter_song2(list_id[0],tab1, tab2)\n",
    "    print \"The length of dataFrame is {}.\".format(len(df))\n",
    "    print \" \"\n",
    "    \n",
    "    if len(list_id) == 1:\n",
    "        print \"We're done\"\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    for i in range(1, len(list_id)):\n",
    "        print \"We completed {} of the total work and now are merging the data frame with id = {}\".format\\\n",
    "        (1.0*i/len(list_id), list_id[i])\n",
    "        \n",
    "        table_name = \"test_01_\" + str(list_id[i])\n",
    "        tab1 = db1[table_name]\n",
    "        tab2 = db2[table_name]\n",
    "        add_df = info_raw_twitter_song2(list_id[i],tab1, tab2)\n",
    "        df = pd.concat([df, add_df])\n",
    "        print \"The length of dataFrame is {}.\".format(len(df))\n",
    "        print \" \"\n",
    "    \n",
    "    df.to_csv(file_name, sep=',', encoding='utf-8')\n",
    "    print \"We're done\"\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are getting data frame for id = 0\n",
      "The length of dataFrame is 668.\n",
      " \n",
      "We completed 0.00684931506849 of the total work and now are merging the data frame with id = 1\n",
      "The length of dataFrame is 5962.\n",
      " \n",
      "We completed 0.013698630137 of the total work and now are merging the data frame with id = 2\n",
      "The length of dataFrame is 10599.\n",
      " \n",
      "We completed 0.0205479452055 of the total work and now are merging the data frame with id = 3\n",
      "The length of dataFrame is 23928.\n",
      " \n",
      "We completed 0.027397260274 of the total work and now are merging the data frame with id = 4\n",
      "The length of dataFrame is 23934.\n",
      " \n",
      "We completed 0.0342465753425 of the total work and now are merging the data frame with id = 5\n",
      "The length of dataFrame is 23999.\n",
      " \n",
      "We completed 0.041095890411 of the total work and now are merging the data frame with id = 6\n",
      "The length of dataFrame is 24051.\n",
      " \n",
      "We completed 0.0479452054795 of the total work and now are merging the data frame with id = 7\n",
      "The length of dataFrame is 24051.\n",
      " \n",
      "We completed 0.0547945205479 of the total work and now are merging the data frame with id = 8\n",
      "The length of dataFrame is 24054.\n",
      " \n",
      "We completed 0.0616438356164 of the total work and now are merging the data frame with id = 9\n",
      "The length of dataFrame is 24065.\n",
      " \n",
      "We completed 0.0684931506849 of the total work and now are merging the data frame with id = 10\n",
      "The length of dataFrame is 24073.\n",
      " \n",
      "We completed 0.0753424657534 of the total work and now are merging the data frame with id = 11\n",
      "The length of dataFrame is 24073.\n",
      " \n",
      "We completed 0.0821917808219 of the total work and now are merging the data frame with id = 12\n",
      "The length of dataFrame is 24123.\n",
      " \n",
      "We completed 0.0890410958904 of the total work and now are merging the data frame with id = 13\n",
      "The length of dataFrame is 24133.\n",
      " \n",
      "We completed 0.0958904109589 of the total work and now are merging the data frame with id = 14\n",
      "The length of dataFrame is 24133.\n",
      " \n",
      "We completed 0.102739726027 of the total work and now are merging the data frame with id = 15\n",
      "The length of dataFrame is 24133.\n",
      " \n",
      "We completed 0.109589041096 of the total work and now are merging the data frame with id = 16\n",
      "The length of dataFrame is 24306.\n",
      " \n",
      "We completed 0.116438356164 of the total work and now are merging the data frame with id = 17\n",
      "The length of dataFrame is 24329.\n",
      " \n",
      "We completed 0.123287671233 of the total work and now are merging the data frame with id = 18\n",
      "The length of dataFrame is 24329.\n",
      " \n",
      "We completed 0.130136986301 of the total work and now are merging the data frame with id = 19\n",
      "The length of dataFrame is 24329.\n",
      " \n",
      "We completed 0.13698630137 of the total work and now are merging the data frame with id = 20\n",
      "The length of dataFrame is 24427.\n",
      " \n",
      "We completed 0.143835616438 of the total work and now are merging the data frame with id = 21\n",
      "The length of dataFrame is 24432.\n",
      " \n",
      "We completed 0.150684931507 of the total work and now are merging the data frame with id = 22\n",
      "The length of dataFrame is 27035.\n",
      " \n",
      "We completed 0.157534246575 of the total work and now are merging the data frame with id = 23\n",
      "The length of dataFrame is 27094.\n",
      " \n",
      "We completed 0.164383561644 of the total work and now are merging the data frame with id = 24\n",
      "The length of dataFrame is 27700.\n",
      " \n",
      "We completed 0.171232876712 of the total work and now are merging the data frame with id = 25\n",
      "The length of dataFrame is 35260.\n",
      " \n",
      "We completed 0.178082191781 of the total work and now are merging the data frame with id = 26\n",
      "The length of dataFrame is 35264.\n",
      " \n",
      "We completed 0.184931506849 of the total work and now are merging the data frame with id = 27\n",
      "The length of dataFrame is 35457.\n",
      " \n",
      "We completed 0.191780821918 of the total work and now are merging the data frame with id = 28\n",
      "The length of dataFrame is 35457.\n",
      " \n",
      "We completed 0.198630136986 of the total work and now are merging the data frame with id = 29\n",
      "The length of dataFrame is 35518.\n",
      " \n",
      "We completed 0.205479452055 of the total work and now are merging the data frame with id = 30\n",
      "The length of dataFrame is 35649.\n",
      " \n",
      "We completed 0.212328767123 of the total work and now are merging the data frame with id = 31\n",
      "The length of dataFrame is 35688.\n",
      " \n",
      "We completed 0.219178082192 of the total work and now are merging the data frame with id = 32\n",
      "The length of dataFrame is 35689.\n",
      " \n",
      "We completed 0.22602739726 of the total work and now are merging the data frame with id = 33\n",
      "The length of dataFrame is 35716.\n",
      " \n",
      "We completed 0.232876712329 of the total work and now are merging the data frame with id = 34\n",
      "The length of dataFrame is 42812.\n",
      " \n",
      "We completed 0.239726027397 of the total work and now are merging the data frame with id = 35\n",
      "The length of dataFrame is 47061.\n",
      " \n",
      "We completed 0.246575342466 of the total work and now are merging the data frame with id = 36\n",
      "The length of dataFrame is 47061.\n",
      " \n",
      "We completed 0.253424657534 of the total work and now are merging the data frame with id = 37\n",
      "The length of dataFrame is 47061.\n",
      " \n",
      "We completed 0.260273972603 of the total work and now are merging the data frame with id = 38\n",
      "The length of dataFrame is 50174.\n",
      " \n",
      "We completed 0.267123287671 of the total work and now are merging the data frame with id = 39\n",
      "The length of dataFrame is 50222.\n",
      " \n",
      "We completed 0.27397260274 of the total work and now are merging the data frame with id = 40\n",
      "The length of dataFrame is 50287.\n",
      " \n",
      "We completed 0.280821917808 of the total work and now are merging the data frame with id = 41\n",
      "The length of dataFrame is 50347.\n",
      " \n",
      "We completed 0.287671232877 of the total work and now are merging the data frame with id = 42\n",
      "The length of dataFrame is 50347.\n",
      " \n",
      "We completed 0.294520547945 of the total work and now are merging the data frame with id = 43\n",
      "The length of dataFrame is 50347.\n",
      " \n",
      "We completed 0.301369863014 of the total work and now are merging the data frame with id = 44\n",
      "The length of dataFrame is 50423.\n",
      " \n",
      "We completed 0.308219178082 of the total work and now are merging the data frame with id = 45\n",
      "The length of dataFrame is 50423.\n",
      " \n",
      "We completed 0.315068493151 of the total work and now are merging the data frame with id = 46\n",
      "The length of dataFrame is 50430.\n",
      " \n",
      "We completed 0.321917808219 of the total work and now are merging the data frame with id = 47\n",
      "The length of dataFrame is 50430.\n",
      " \n",
      "We completed 0.328767123288 of the total work and now are merging the data frame with id = 48\n",
      "The length of dataFrame is 52436.\n",
      " \n",
      "We completed 0.335616438356 of the total work and now are merging the data frame with id = 49\n",
      "The length of dataFrame is 52483.\n",
      " \n",
      "We completed 0.342465753425 of the total work and now are merging the data frame with id = 50\n",
      "The length of dataFrame is 52535.\n",
      " \n",
      "We completed 0.349315068493 of the total work and now are merging the data frame with id = 51\n",
      "The length of dataFrame is 52759.\n",
      " \n",
      "We completed 0.356164383562 of the total work and now are merging the data frame with id = 52\n",
      "The length of dataFrame is 52779.\n",
      " \n",
      "We completed 0.36301369863 of the total work and now are merging the data frame with id = 53\n",
      "The length of dataFrame is 52779.\n",
      " \n",
      "We completed 0.369863013699 of the total work and now are merging the data frame with id = 54\n",
      "The length of dataFrame is 52804.\n",
      " \n",
      "We completed 0.376712328767 of the total work and now are merging the data frame with id = 55\n",
      "The length of dataFrame is 52813.\n",
      " \n",
      "We completed 0.383561643836 of the total work and now are merging the data frame with id = 56\n",
      "The length of dataFrame is 52844.\n",
      " \n",
      "We completed 0.390410958904 of the total work and now are merging the data frame with id = 57\n",
      "The length of dataFrame is 52844.\n",
      " \n",
      "We completed 0.397260273973 of the total work and now are merging the data frame with id = 58\n",
      "The length of dataFrame is 52844.\n",
      " \n",
      "We completed 0.404109589041 of the total work and now are merging the data frame with id = 59\n",
      "The length of dataFrame is 52844.\n",
      " \n",
      "We completed 0.41095890411 of the total work and now are merging the data frame with id = 60\n",
      "The length of dataFrame is 52904.\n",
      " \n",
      "We completed 0.417808219178 of the total work and now are merging the data frame with id = 61\n",
      "The length of dataFrame is 52964.\n",
      " \n",
      "We completed 0.424657534247 of the total work and now are merging the data frame with id = 62\n",
      "The length of dataFrame is 52967.\n",
      " \n",
      "We completed 0.431506849315 of the total work and now are merging the data frame with id = 63\n",
      "The length of dataFrame is 61987.\n",
      " \n",
      "We completed 0.438356164384 of the total work and now are merging the data frame with id = 64\n",
      "The length of dataFrame is 61987.\n",
      " \n",
      "We completed 0.445205479452 of the total work and now are merging the data frame with id = 65\n",
      "The length of dataFrame is 62082.\n",
      " \n",
      "We completed 0.452054794521 of the total work and now are merging the data frame with id = 66\n",
      "The length of dataFrame is 62082.\n",
      " \n",
      "We completed 0.458904109589 of the total work and now are merging the data frame with id = 67\n",
      "The length of dataFrame is 62087.\n",
      " \n",
      "We completed 0.465753424658 of the total work and now are merging the data frame with id = 68\n",
      "The length of dataFrame is 62144.\n",
      " \n",
      "We completed 0.472602739726 of the total work and now are merging the data frame with id = 69\n",
      "The length of dataFrame is 62149.\n",
      " \n",
      "We completed 0.479452054795 of the total work and now are merging the data frame with id = 70\n",
      "The length of dataFrame is 71455.\n",
      " \n",
      "We completed 0.486301369863 of the total work and now are merging the data frame with id = 71\n",
      "The length of dataFrame is 71455.\n",
      " \n",
      "We completed 0.493150684932 of the total work and now are merging the data frame with id = 72\n",
      "The length of dataFrame is 71455.\n",
      " \n",
      "We completed 0.5 of the total work and now are merging the data frame with id = 73\n",
      "The length of dataFrame is 71458.\n",
      " \n",
      "We completed 0.506849315068 of the total work and now are merging the data frame with id = 74\n",
      "The length of dataFrame is 71536.\n",
      " \n",
      "We completed 0.513698630137 of the total work and now are merging the data frame with id = 75\n",
      "The length of dataFrame is 71565.\n",
      " \n",
      "We completed 0.520547945205 of the total work and now are merging the data frame with id = 76\n",
      "The length of dataFrame is 71570.\n",
      " \n",
      "We completed 0.527397260274 of the total work and now are merging the data frame with id = 77\n",
      "The length of dataFrame is 71573.\n",
      " \n",
      "We completed 0.534246575342 of the total work and now are merging the data frame with id = 78\n",
      "The length of dataFrame is 71750.\n",
      " \n",
      "We completed 0.541095890411 of the total work and now are merging the data frame with id = 79\n",
      "The length of dataFrame is 71751.\n",
      " \n",
      "We completed 0.547945205479 of the total work and now are merging the data frame with id = 80\n",
      "The length of dataFrame is 71751.\n",
      " \n",
      "We completed 0.554794520548 of the total work and now are merging the data frame with id = 81\n",
      "The length of dataFrame is 71751.\n",
      " \n",
      "We completed 0.561643835616 of the total work and now are merging the data frame with id = 82\n",
      "The length of dataFrame is 71807.\n",
      " \n",
      "We completed 0.568493150685 of the total work and now are merging the data frame with id = 83\n",
      "The length of dataFrame is 71807.\n",
      " \n",
      "We completed 0.575342465753 of the total work and now are merging the data frame with id = 84\n",
      "The length of dataFrame is 71867.\n",
      " \n",
      "We completed 0.582191780822 of the total work and now are merging the data frame with id = 85\n",
      "The length of dataFrame is 71918.\n",
      " \n",
      "We completed 0.58904109589 of the total work and now are merging the data frame with id = 86\n",
      "The length of dataFrame is 71971.\n",
      " \n",
      "We completed 0.595890410959 of the total work and now are merging the data frame with id = 87\n",
      "The length of dataFrame is 71971.\n",
      " \n",
      "We completed 0.602739726027 of the total work and now are merging the data frame with id = 88\n",
      "The length of dataFrame is 72033.\n",
      " \n",
      "We completed 0.609589041096 of the total work and now are merging the data frame with id = 89\n",
      "The length of dataFrame is 74916.\n",
      " \n",
      "We completed 0.616438356164 of the total work and now are merging the data frame with id = 90\n",
      "The length of dataFrame is 74916.\n",
      " \n",
      "We completed 0.623287671233 of the total work and now are merging the data frame with id = 91\n",
      "The length of dataFrame is 74930.\n",
      " \n",
      "We completed 0.630136986301 of the total work and now are merging the data frame with id = 92\n",
      "The length of dataFrame is 74932.\n",
      " \n",
      "We completed 0.63698630137 of the total work and now are merging the data frame with id = 93\n",
      "The length of dataFrame is 74990.\n",
      " \n",
      "We completed 0.643835616438 of the total work and now are merging the data frame with id = 94\n",
      "The length of dataFrame is 75280.\n",
      " \n",
      "We completed 0.650684931507 of the total work and now are merging the data frame with id = 95\n",
      "The length of dataFrame is 75287.\n",
      " \n",
      "We completed 0.657534246575 of the total work and now are merging the data frame with id = 96\n",
      "The length of dataFrame is 79496.\n",
      " \n",
      "We completed 0.664383561644 of the total work and now are merging the data frame with id = 97\n",
      "The length of dataFrame is 79558.\n",
      " \n",
      "We completed 0.671232876712 of the total work and now are merging the data frame with id = 98\n",
      "The length of dataFrame is 79558.\n",
      " \n",
      "We completed 0.678082191781 of the total work and now are merging the data frame with id = 99\n",
      "The length of dataFrame is 79604.\n",
      " \n",
      "We completed 0.684931506849 of the total work and now are merging the data frame with id = 100\n",
      "The length of dataFrame is 79693.\n",
      " \n",
      "We completed 0.691780821918 of the total work and now are merging the data frame with id = 101\n",
      "The length of dataFrame is 79695.\n",
      " \n",
      "We completed 0.698630136986 of the total work and now are merging the data frame with id = 102\n",
      "The length of dataFrame is 79733.\n",
      " \n",
      "We completed 0.705479452055 of the total work and now are merging the data frame with id = 103\n",
      "The length of dataFrame is 79910.\n",
      " \n",
      "We completed 0.712328767123 of the total work and now are merging the data frame with id = 104\n",
      "The length of dataFrame is 79918.\n",
      " \n",
      "We completed 0.719178082192 of the total work and now are merging the data frame with id = 105\n",
      "The length of dataFrame is 79921.\n",
      " \n",
      "We completed 0.72602739726 of the total work and now are merging the data frame with id = 106\n",
      "The length of dataFrame is 79923.\n",
      " \n",
      "We completed 0.732876712329 of the total work and now are merging the data frame with id = 107\n",
      "The length of dataFrame is 79989.\n",
      " \n",
      "We completed 0.739726027397 of the total work and now are merging the data frame with id = 108\n",
      "The length of dataFrame is 80003.\n",
      " \n",
      "We completed 0.746575342466 of the total work and now are merging the data frame with id = 109\n",
      "The length of dataFrame is 80003.\n",
      " \n",
      "We completed 0.753424657534 of the total work and now are merging the data frame with id = 110\n",
      "The length of dataFrame is 80005.\n",
      " \n",
      "We completed 0.760273972603 of the total work and now are merging the data frame with id = 111\n",
      "The length of dataFrame is 80006.\n",
      " \n",
      "We completed 0.767123287671 of the total work and now are merging the data frame with id = 112\n",
      "The length of dataFrame is 80006.\n",
      " \n",
      "We completed 0.77397260274 of the total work and now are merging the data frame with id = 113\n",
      "The length of dataFrame is 82273.\n",
      " \n",
      "We completed 0.780821917808 of the total work and now are merging the data frame with id = 114\n",
      "The length of dataFrame is 82330.\n",
      " \n",
      "We completed 0.787671232877 of the total work and now are merging the data frame with id = 115\n",
      "The length of dataFrame is 82330.\n",
      " \n",
      "We completed 0.794520547945 of the total work and now are merging the data frame with id = 116\n",
      "The length of dataFrame is 82609.\n",
      " \n",
      "We completed 0.801369863014 of the total work and now are merging the data frame with id = 117\n",
      "The length of dataFrame is 82668.\n",
      " \n",
      "We completed 0.808219178082 of the total work and now are merging the data frame with id = 118\n",
      "The length of dataFrame is 82749.\n",
      " \n",
      "We completed 0.815068493151 of the total work and now are merging the data frame with id = 119\n",
      "The length of dataFrame is 82755.\n",
      " \n",
      "We completed 0.821917808219 of the total work and now are merging the data frame with id = 120\n",
      "The length of dataFrame is 90502.\n",
      " \n",
      "We completed 0.828767123288 of the total work and now are merging the data frame with id = 121\n",
      "The length of dataFrame is 91368.\n",
      " \n",
      "We completed 0.835616438356 of the total work and now are merging the data frame with id = 122\n",
      "The length of dataFrame is 92205.\n",
      " \n",
      "We completed 0.842465753425 of the total work and now are merging the data frame with id = 123\n",
      "The length of dataFrame is 92221.\n",
      " \n",
      "We completed 0.849315068493 of the total work and now are merging the data frame with id = 124\n",
      "The length of dataFrame is 92256.\n",
      " \n",
      "We completed 0.856164383562 of the total work and now are merging the data frame with id = 125\n",
      "The length of dataFrame is 92256.\n",
      " \n",
      "We completed 0.86301369863 of the total work and now are merging the data frame with id = 126\n",
      "The length of dataFrame is 92256.\n",
      " \n",
      "We completed 0.869863013699 of the total work and now are merging the data frame with id = 127\n",
      "The length of dataFrame is 92259.\n",
      " \n",
      "We completed 0.876712328767 of the total work and now are merging the data frame with id = 128\n",
      "The length of dataFrame is 92278.\n",
      " \n",
      "We completed 0.883561643836 of the total work and now are merging the data frame with id = 129\n",
      "The length of dataFrame is 92278.\n",
      " \n",
      "We completed 0.890410958904 of the total work and now are merging the data frame with id = 130\n",
      "The length of dataFrame is 92278.\n",
      " \n",
      "We completed 0.897260273973 of the total work and now are merging the data frame with id = 131\n",
      "The length of dataFrame is 92284.\n",
      " \n",
      "We completed 0.904109589041 of the total work and now are merging the data frame with id = 132\n",
      "The length of dataFrame is 92298.\n",
      " \n",
      "We completed 0.91095890411 of the total work and now are merging the data frame with id = 133\n",
      "The length of dataFrame is 92304.\n",
      " \n",
      "We completed 0.917808219178 of the total work and now are merging the data frame with id = 134\n",
      "The length of dataFrame is 92306.\n",
      " \n",
      "We completed 0.924657534247 of the total work and now are merging the data frame with id = 135\n",
      "The length of dataFrame is 92306.\n",
      " \n",
      "We completed 0.931506849315 of the total work and now are merging the data frame with id = 136\n",
      "The length of dataFrame is 92347.\n",
      " \n",
      "We completed 0.938356164384 of the total work and now are merging the data frame with id = 137\n",
      "The length of dataFrame is 92395.\n",
      " \n",
      "We completed 0.945205479452 of the total work and now are merging the data frame with id = 138\n",
      "The length of dataFrame is 92397.\n",
      " \n",
      "We completed 0.952054794521 of the total work and now are merging the data frame with id = 139\n",
      "The length of dataFrame is 92402.\n",
      " \n",
      "We completed 0.958904109589 of the total work and now are merging the data frame with id = 140\n",
      "The length of dataFrame is 92405.\n",
      " \n",
      "We completed 0.965753424658 of the total work and now are merging the data frame with id = 141\n",
      "The length of dataFrame is 92405.\n",
      " \n",
      "We completed 0.972602739726 of the total work and now are merging the data frame with id = 142\n",
      "The length of dataFrame is 92481.\n",
      " \n",
      "We completed 0.979452054795 of the total work and now are merging the data frame with id = 143\n",
      "The length of dataFrame is 102535.\n",
      " \n",
      "We completed 0.986301369863 of the total work and now are merging the data frame with id = 144\n",
      "The length of dataFrame is 102535.\n",
      " \n",
      "We completed 0.993150684932 of the total work and now are merging the data frame with id = 145\n",
      "The length of dataFrame is 109410.\n",
      " \n",
      "We're done\n"
     ]
    }
   ],
   "source": [
    "db1 = client['song3_database']\n",
    "db2 = client['song4_database']\n",
    "list_input = get_billboard(\"../data/billboard.csv\")\n",
    "list_id = range(len(list_input))\n",
    "file_name = '../data_result_raw_song_3_4_9_03.csv' \n",
    "df_raw_total = merge_raw_dataframe2(list_id, db1, db2, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
